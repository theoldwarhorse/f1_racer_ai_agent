# F1 Social Media Agent
The f1 social media agent is an AI agent that creates, comments on and likes social media posts.
The posts and comments are written in a tone that mimics the persona of a formula one driver.
The posts include specific reference to the weekend sessions by mentioning finishing positions and weather. 
The posts include hashtags and mentions of other drivers.

## Technical Description
The repo is composed of the following extendable python packages.
1. Large Language Models: Implements both the model zephyr-7b-beta from Hugging Face and a mock client.  
2. Weekend Simulators: Generate a piece of Json that describes the weekend results for each session. 
Data includes weather during the session, the position the driver finished and which other driver topped the session.
3. Social Media Clients: Composed of a large language model and logic for creating prompts from the weekend simulation. 
Data this class is responsible for generating is the posts, comments and likes.
4. The code can be run by running the f1_races_ai_agent.py file.
5. The output can be visualised by running the streamlit app in the f1_races_ai_agent_visual.py file.

The structure of the above packages follows a uniform convention. 
There is a config file where constants are stored. Each package contains an implementation for each concept. 
Should a developer want to add their own implementation this can be done by extending the appropriate folder.
The large language model is an example of this. The mock client can be easily substituted.
The code is structured in the standard object orientated structure.
The domain classes for each package leverages inheritance by extending the associated config classes.


## Running the agent with docker (for users)
To run the app locally.
1. Clone the GitHub repo.
2. Build the container: docker build -t aiagent:1.0.0 .
3. Run the container to expose the streamlit frontend on http://localhost:8501: docker run -d -p 8501:8501 aiagent:1.0.0
4. Get the container_id: docker ps
5. login to the container to run the model: docker exec -it <container_id> bash
6. Run model: python3 -m f1_agent
Note running the model may take a some time depending on the spects of your machine.
If you have a GPU it may take between 10 and 15 minutes.
If you do not have a GPU it is recommended you use the mock client and sample data.

## How to run the agent without docker (for developers)
The agent leverages the model "HuggingFaceH4/zephyr-7b-beta". 
This can take long to run depending on the machine because the model runs locally. 
If you have a GPU to may take between 10 and 15 minutes. 
Without a GPU you are recommended to use the mock client and reference the sample responses. 
To simulate a response from the model you can invoke the mock_client. 
To do so navigate to the f1_agent.py file, comment out line one and uncomment line two.
To run the agent and generate the responses simply run py -m f1_agent. 
When the script runs it will generate a piece of json which is written to the file: weekend_context.json
The repo also includes a mock weekend_context_mock and two samples weekend_context_sample_1 and weekend_context_sample_2
These json files include the data from the race weekend such as the weather and position of the driver Speedy Quick.
It also includes the social media posts made by speedy Quick, the fans, Speedy's responses and reactions.
This output is best viewed in the streamlit frontend. 
Which can run by the following. py -m streamlit run f1_agent_visual.py

## The streamlit frontend 
The frontend is designed as a convenient way to visualize the data. 
The app gives the user the ability to visualize different data sets.
Available data sets include sampledata generated by the author, mockdata and data generated by running the agent.

## Challenges and feedback 
This was a great coding challenge and an excellent way to showcase skills in the following.
1. Locally running models. 
2. Natural language processing. 
3. Prompt generation and prompt management. 
4. Data visualization.
5. Software engineering skills.

The challenges I faced were.
1. Getting the model to produce authentic social media posts. 
Without proper prompts the posts were repetative and unrealistic. 
2. Limited hardware. 
Unfortunately I had to run all the code on a laptop without a GPU. 
It took long to generate model responses.

My favorite part of the challenge was the natural language processing used for building up the prompts.
I enjoyed writing well structured, clean code and building a frontend for visuals.

Thank you for the opportunity!
